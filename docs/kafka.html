<p>Apache Kafka
- <a href="#1-writing-messages-to-kafka">1. Writing messages to Kafka</a>
  - <a href="#11-producers">1.1. Producers</a>
  - <a href="#12-topics">1.2. Topics</a>
  - <a href="#13-partitions">1.3. Partitions</a>
  - <a href="#14-replication">1.4. Replication</a>
- <a href="#2-reading-data-from-kafka">2. Reading Data from Kafka</a>
  - <a href="#21-consumers">2.1. Consumers</a>
  - <a href="#22-consumer-groups">2.2. Consumer groups</a>
  - <a href="#23-offsets">2.3. Offsets</a>
  - <a href="#24-heartbeat">2.4. Heartbeat</a>
- <a href="#3-kafka-internals">3. Kafka Internals</a>
  - <a href="#31-broker">3.1. Broker</a>
  - <a href="#32-zookeeper">3.2. Zookeeper</a>
  - <a href="#33-log">3.3. Log</a>
  - <a href="#34-replication">3.4. Replication</a>
- <a href="#4-reliable-data-delivery">4. Reliable Data Delivery</a>
  - <a href="#41-exactly-once-semantics">4.1. Exactly-once semantics</a>
  - <a href="#42-at-least-once-semantics">4.2. At-least-once semantics</a>
  - <a href="#43-at-most-once-semantics">4.3. At-most-once semantics</a>
- <a href="#5-building-data-pipelines">5. Building Data pipelines</a>
  - <a href="#51-kafka-connect">5.1. Kafka Connect</a>
  - <a href="#52-kafka-streams">5.2. Kafka Streams</a>
- <a href="#6-monitoring-kafka">6. Monitoring Kafka</a>
  - <a href="#61-jmx">6.1. JMX</a>
  - <a href="#62-prometheus">6.2. Prometheus</a>
  - <a href="#63-grafana">6.3. Grafana</a>
- <a href="#7-streaming-processing">7. Streaming Processing</a>
  - <a href="#71-apache-spark">7.1. Apache Spark</a>
  - <a href="#72-apache-flink">7.2. Apache Flink</a>
  - <a href="#73-amazon-kinesis">7.3. Amazon Kinesis</a></p>

<h1>1. Writing messages to Kafka</h1>

<h2>1.1. Producers</h2>

<ul>
<li>Write messages to Kafka topics.</li>
<li><p>Can be configured to use a variety of serialization formats.</p>

<h2>1.2. Topics</h2></li>
<li><p>A logical grouping of messages.</p></li>
<li><p>Can be partitioned to improve scalability.</p>

<h2>1.3. Partitions</h2></li>
<li><p>A physical division of a topic.</p></li>
<li><p>Messages are distributed across partitions based on a hash of their key.</p>

<h2>1.4. Replication</h2></li>
<li><p>Each partition is replicated to a number of brokers.</p></li>
<li>This ensures that messages are not lost if a broker fails.</li>
</ul>

<h1>2. Reading Data from Kafka</h1>

<h2>2.1. Consumers</h2>

<ul>
<li>Read messages from Kafka topics.</li>
<li><p>Can be configured to use a variety of consumer groups.</p>

<h2>2.2. Consumer groups</h2></li>
<li><p>A group of consumers that read from the same topic.</p></li>
<li><p>Messages are distributed across consumers in the group.</p>

<h2>2.3. Offsets</h2></li>
<li><p>The position in a partition where a consumer is reading from.</p></li>
<li><p>Offsets are maintained by Kafka and are used to resume reading from where a consumer left off.</p>

<h2>2.4. Heartbeat</h2></li>
<li><p>A periodic message that consumers send to Kafka to indicate that they are still alive.</p></li>
<li>If a consumer fails to send a heartbeat, Kafka will mark it as dead and stop sending it messages.</li>
</ul>

<h1>3. Kafka Internals</h1>

<h2>3.1. Broker</h2>

<ul>
<li>A server that runs Kafka.</li>
<li><p>Brokers are responsible for storing messages, replicating them to other brokers, and serving them to consumers.</p>

<h2>3.2. Zookeeper</h2></li>
<li><p>A distributed coordination service that Kafka uses to store metadata about its topics, brokers, and consumers.</p>

<h2>3.3. Log</h2></li>
<li><p>A circular log that stores messages.</p></li>
<li><p>Messages are appended to the log in a append-only fashion.</p>

<h2>3.4. Replication</h2></li>
<li><p>Each partition is replicated to a number of brokers.</p></li>
<li>This ensures that messages are not lost if a broker fails.</li>
</ul>

<h1>4. Reliable Data Delivery</h1>

<h2>4.1. Exactly-once semantics</h2>

<ul>
<li>Guarantees that messages are delivered exactly once.</li>
<li><p>This is the most reliable delivery semantics, but it can be the most expensive.</p>

<h2>4.2. At-least-once semantics</h2></li>
<li><p>Guarantees that messages are delivered at least once.</p></li>
<li><p>This is a less expensive delivery semantics than exactly-once, but it can result in duplicate messages.</p>

<h2>4.3. At-most-once semantics</h2></li>
<li><p>Guarantees that messages are delivered at most once.</p></li>
<li>This is the least expensive delivery semantics, but it can result in lost messages.</li>
</ul>

<h1>5. Building Data pipelines</h1>

<h2>5.1. Kafka Connect</h2>

<ul>
<li><p>A framework for building and managing data pipelines that connect Kafka to other data sources and sinks.</p>

<h2>5.2. Kafka Streams</h2></li>
<li><p>A library for building real-time streaming applications that process data from Kafka.</p></li>
</ul>

<h1>6. Monitoring Kafka</h1>

<h2>6.1. JMX</h2>

<ul>
<li><p>A Java Management Extensions (JMX) console that can be used to monitor Kafka brokers.</p>

<h2>6.2. Prometheus</h2></li>
<li><p>An open-source monitoring system that can be used to collect metrics from Kafka brokers.</p>

<h2>6.3. Grafana</h2></li>
<li><p>A visualization tool that can be used to display metrics collected by Prometheus.</p></li>
</ul>

<h1>7. Streaming Processing</h1>

<h2>7.1. Apache Spark</h2>

<ul>
<li><p>A distributed processing framework that can be used to process streaming data from Kafka.</p>

<h2>7.2. Apache Flink</h2></li>
<li><p>A distributed processing framework that can be used to process streaming data from Kafka.</p>

<h2>7.3. Amazon Kinesis</h2></li>
<li><p>A fully-managed service that can be used to process streaming data from Kafka.</p></li>
</ul>
